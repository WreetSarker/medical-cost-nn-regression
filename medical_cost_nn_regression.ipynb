{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medical_cost_nn_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4fZYBxXmBe6"
      },
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "s_VaEip4nYVJ",
        "outputId": "2d6af5fe-8f63-4668-dbff-f2d98ae0284b"
      },
      "source": [
        "# Read the dataset\n",
        "insurance = pd.read_csv(\"insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcpzTbJMnqv9"
      },
      "source": [
        "We need to convert our categorical data into numerical data. For this, we will use pandas `get_dummies` method to convert categorical data into numerical data by one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "59-7vCX8uFV8",
        "outputId": "d7aa9a5d-401e-4910-ee87-e8ade683d573"
      },
      "source": [
        "# One hot encoding our DataFrame\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlI5CcgHuQV5"
      },
      "source": [
        "Creating **Features** (X) and **Labels**(y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKr5OBHIvqMV"
      },
      "source": [
        "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
        "y = insurance_one_hot[\"charges\"]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "A7GWph8-wkPv",
        "outputId": "45fdcbca-dc1b-44de-e1f7-c743528f9123"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgzDUgExwlrk",
        "outputId": "79a8b7db-31e8-47c7-ac7f-a43956c5d008"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJmvoZudwocI"
      },
      "source": [
        "Now let's create a train and test set. For this, we will use sklearn's `train_test_split`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj1ZlU1Dw55N"
      },
      "source": [
        "# Import train_test_split and split the data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrU3dLLByc7D",
        "outputId": "690cd7ab-eff6-4469-8637-43688880b41f"
      },
      "source": [
        "# Let's check the shapes of our split data set\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 11), (1070,), (268, 11), (268,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA-_uWyBysuQ",
        "outputId": "721b3757-83b1-47ec-95f5-3b37afe8597c"
      },
      "source": [
        "# Now let's build a neural network for this data\n",
        "tf.random.set_seed=42\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8874.0752 - mae: 8874.0752\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7675.4580 - mae: 7675.4580\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7464.8530 - mae: 7464.8530\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.6748 - mae: 7578.6748\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7791.2998 - mae: 7791.2998\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7558.6509 - mae: 7558.6509\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7695.3848 - mae: 7695.3848\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7495.0962 - mae: 7495.0962\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7746.2070 - mae: 7746.2070\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7589.4253 - mae: 7589.4253\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7874.7095 - mae: 7874.7095\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7731.3154 - mae: 7731.3154\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7685.0820 - mae: 7685.0820\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7475.0386 - mae: 7475.0386\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7510.2173 - mae: 7510.2173\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7708.4946 - mae: 7708.4946\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7697.4160 - mae: 7697.4160\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7626.1724 - mae: 7626.1724\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7545.5269 - mae: 7545.5269\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7644.9585 - mae: 7644.9585\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7754.4224 - mae: 7754.4224\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7799.9854 - mae: 7799.9854\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7557.8262 - mae: 7557.8262\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7642.6982 - mae: 7642.6982\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7556.0132 - mae: 7556.0132\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7641.7090 - mae: 7641.7090\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7632.9619 - mae: 7632.9619\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7774.6055 - mae: 7774.6055\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7645.3818 - mae: 7645.3818\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7529.3750 - mae: 7529.3750\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7736.5049 - mae: 7736.5049\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7698.3481 - mae: 7698.3481\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7610.5176 - mae: 7610.5176\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7638.0166 - mae: 7638.0166\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7436.0059 - mae: 7436.0059\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7706.2773 - mae: 7706.2773\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7434.2471 - mae: 7434.2471\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7422.0776 - mae: 7422.0776\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7340.3218 - mae: 7340.3218\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7555.0996 - mae: 7555.0996\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7408.5938 - mae: 7408.5938\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.5967 - mae: 7523.5967\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7507.3276 - mae: 7507.3276\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7364.5664 - mae: 7364.5664\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7550.9824 - mae: 7550.9824\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7438.9131 - mae: 7438.9131\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7653.0312 - mae: 7653.0312\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7648.4463 - mae: 7648.4463\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7601.2261 - mae: 7601.2261\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7324.1050 - mae: 7324.1050\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7445.4907 - mae: 7445.4907\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7380.5210 - mae: 7380.5210\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7445.5469 - mae: 7445.5469\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7447.6738 - mae: 7447.6738\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7298.0410 - mae: 7298.0410\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7450.3550 - mae: 7450.3550\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7507.7417 - mae: 7507.7417\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7434.4858 - mae: 7434.4858\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7321.7783 - mae: 7321.7783\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7446.8608 - mae: 7446.8608\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7481.1274 - mae: 7481.1274\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7283.8750 - mae: 7283.8750\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7328.7285 - mae: 7328.7285\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7404.7803 - mae: 7404.7803\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7318.5645 - mae: 7318.5645\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7371.0474 - mae: 7371.0474\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7561.2661 - mae: 7561.2661\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7490.3618 - mae: 7490.3618\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7293.1597 - mae: 7293.1597\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7575.9688 - mae: 7575.9688\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7332.9751 - mae: 7332.9751\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7263.4653 - mae: 7263.4653\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7368.5991 - mae: 7368.5991\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7264.3057 - mae: 7264.3057\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7430.5791 - mae: 7430.5791\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7378.0332 - mae: 7378.0332\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.7036 - mae: 7537.7036\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7085.6025 - mae: 7085.6025\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7394.8496 - mae: 7394.8496\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7341.1792 - mae: 7341.1792\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7181.1934 - mae: 7181.1934\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7331.5215 - mae: 7331.5215\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7483.0605 - mae: 7483.0605\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7223.4634 - mae: 7223.4634\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7600.2646 - mae: 7600.2646\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7545.9370 - mae: 7545.9370\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7306.1094 - mae: 7306.1094\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7369.8037 - mae: 7369.8037\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7154.6943 - mae: 7154.6943\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7075.6602 - mae: 7075.6602\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7469.7051 - mae: 7469.7051\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7256.0098 - mae: 7256.0098\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7561.3916 - mae: 7561.3916\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7279.7432 - mae: 7279.7432\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7383.5327 - mae: 7383.5327\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7556.0991 - mae: 7556.0991\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7255.0537 - mae: 7255.0537\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7066.4873 - mae: 7066.4873\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7119.2231 - mae: 7119.2231\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7347.1284 - mae: 7347.1284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0fb4275e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNSgV9c117U2",
        "outputId": "47428270-8d98-44e1-ebfb-25922fc9d554"
      },
      "source": [
        "# Check the results of our model with test data\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7982.7554 - mae: 7982.7554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7982.75537109375, 7982.75537109375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_s7x3Aq28CJ"
      },
      "source": [
        "Well, it seems that the model is not performing up to the mark ! Let's tweak the model a bit and see if we get a better result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InWHs0RW32fY",
        "outputId": "1c190012-d33b-4846-f447-f396ac69838d"
      },
      "source": [
        "# Let's try a model with a higher hidden layer and relu activation\n",
        "tf.random.set_seed=42\n",
        "# 1.Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(X_train, y_train, epochs = 100)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 14308.2432 - mae: 14308.2432\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13345.4922 - mae: 13345.4922\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13344.9990 - mae: 13344.9990\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13344.3750 - mae: 13344.3750\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13343.4873 - mae: 13343.4873\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13342.0732 - mae: 13342.0732\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13339.6230 - mae: 13339.6230\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13335.1406 - mae: 13335.1406\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13326.6426 - mae: 13326.6426\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13310.2520 - mae: 13310.2520\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13278.3438 - mae: 13278.3438\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13215.9023 - mae: 13215.9023\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13093.3945 - mae: 13093.3945\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12852.7217 - mae: 12852.7217\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12380.2666 - mae: 12380.2666\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 11534.6670 - mae: 11534.6670\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 10499.8428 - mae: 10499.8428\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9520.2061 - mae: 9520.2061\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8827.9414 - mae: 8827.9414\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8484.3779 - mae: 8484.3779\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8343.7207 - mae: 8343.7207\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8301.9482 - mae: 8301.9482\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8291.9580 - mae: 8291.9580\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8286.3828 - mae: 8286.3828\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.8281 - mae: 8284.8281\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8285.6865 - mae: 8285.6865\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.8096 - mae: 8284.8096\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.9775 - mae: 8283.9775\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.8877 - mae: 8283.8877\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.7324 - mae: 8282.7324\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8281.9883 - mae: 8281.9883\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8285.6846 - mae: 8285.6846\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8281.9043 - mae: 8281.9043\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.6309 - mae: 8283.6309\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.8770 - mae: 8283.8770\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.5225 - mae: 8283.5225\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.9355 - mae: 8282.9355\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.8809 - mae: 8283.8809\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.6006 - mae: 8282.6006\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.7871 - mae: 8282.7871\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.8809 - mae: 8283.8809\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.9307 - mae: 8282.9307\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.3271 - mae: 8283.3271\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.4326 - mae: 8284.4326\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.4561 - mae: 8284.4561\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8285.2646 - mae: 8285.2646\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.2646 - mae: 8283.2646\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.1631 - mae: 8283.1631\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.0098 - mae: 8284.0098\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.2412 - mae: 8283.2412\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.3438 - mae: 8283.3438\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.4785 - mae: 8283.4785\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.1631 - mae: 8282.1631\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.2539 - mae: 8284.2539\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.0479 - mae: 8283.0479\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.2285 - mae: 8283.2285\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.1582 - mae: 8283.1582\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.9473 - mae: 8282.9473\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.6348 - mae: 8283.6348\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.9072 - mae: 8284.9072\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.5762 - mae: 8283.5762\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.8271 - mae: 8283.8271\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8284.7500 - mae: 8284.7500\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.6660 - mae: 8282.6660\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.0088 - mae: 8282.0088\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.7480 - mae: 8283.7480\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.4248 - mae: 8284.4248\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.2188 - mae: 8283.2188\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.6963 - mae: 8283.6963\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.9238 - mae: 8282.9238\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.1709 - mae: 8283.1709\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.7705 - mae: 8283.7705\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.1973 - mae: 8283.1973\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.0312 - mae: 8284.0312\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.8877 - mae: 8282.8877\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.0068 - mae: 8284.0068\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8285.0781 - mae: 8285.0781\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.5732 - mae: 8283.5732\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.0332 - mae: 8284.0332\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.8770 - mae: 8283.8770\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8284.0654 - mae: 8284.0654\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.0439 - mae: 8283.0439\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.4688 - mae: 8282.4688\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8284.3271 - mae: 8284.3271\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.0322 - mae: 8284.0322\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.5283 - mae: 8283.5283\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.0781 - mae: 8284.0781\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.9541 - mae: 8284.9541\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.9355 - mae: 8284.9355\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.2588 - mae: 8283.2588\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8285.0654 - mae: 8285.0654\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8284.2539 - mae: 8284.2539\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.5557 - mae: 8283.5557\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.3428 - mae: 8283.3428\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.9150 - mae: 8282.9150\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.0645 - mae: 8283.0645\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8282.8350 - mae: 8282.8350\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.7832 - mae: 8283.7832\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8283.1016 - mae: 8283.1016\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8283.3799 - mae: 8283.3799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0fb3129050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx_ZXJlA5-un",
        "outputId": "d1661708-9927-4b49-e2fd-070eba9073ed"
      },
      "source": [
        "# Check the results of our model with test data\n",
        "model_1.evaluate(X_test, y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 8651.7334 - mae: 8651.7334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8651.7333984375, 8651.7333984375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbsIvW-C6ynX",
        "outputId": "1037ad5a-c2e8-4876-f335-0489617a718b"
      },
      "source": [
        "# Let's try a model with a different optimizer\n",
        "tf.random.set_seed=42\n",
        "# 1.Create a model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(X_train, y_train, epochs = 100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13056.1895 - mae: 13056.1895\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9238.7588 - mae: 9238.7588\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7470.2544 - mae: 7470.2544\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7322.2998 - mae: 7322.2998\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7201.9595 - mae: 7201.9595\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7087.5200 - mae: 7087.5200\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6930.0894 - mae: 6930.0894\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6767.2153 - mae: 6767.2153\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6615.3237 - mae: 6615.3237\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6474.4204 - mae: 6474.4204\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6382.2559 - mae: 6382.2559\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6278.2817 - mae: 6278.2817\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6185.1782 - mae: 6185.1782\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6088.6411 - mae: 6088.6411\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5981.2485 - mae: 5981.2485\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5819.2983 - mae: 5819.2983\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5636.0405 - mae: 5636.0405\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5412.4688 - mae: 5412.4688\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5104.8608 - mae: 5104.8608\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4696.1636 - mae: 4696.1636\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4205.0234 - mae: 4205.0234\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3797.3997 - mae: 3797.3997\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3601.7830 - mae: 3601.7830\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3555.9775 - mae: 3555.9775\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3483.5774 - mae: 3483.5774\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3422.8474 - mae: 3422.8474\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3363.7134 - mae: 3363.7134\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3332.0598 - mae: 3332.0598\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3309.3633 - mae: 3309.3633\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3275.5078 - mae: 3275.5078\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3237.5715 - mae: 3237.5715\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3221.7083 - mae: 3221.7083\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3167.0115 - mae: 3167.0115\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3105.1536 - mae: 3105.1536\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3083.2063 - mae: 3083.2063\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3071.1890 - mae: 3071.1890\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2954.2141 - mae: 2954.2141\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2922.9971 - mae: 2922.9971\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2866.0095 - mae: 2866.0095\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2812.7488 - mae: 2812.7488\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2809.7175 - mae: 2809.7175\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2770.4985 - mae: 2770.4985\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2822.1335 - mae: 2822.1335\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2759.5967 - mae: 2759.5967\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2730.2395 - mae: 2730.2395\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2734.1528 - mae: 2734.1528\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2735.0735 - mae: 2735.0735\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2694.2417 - mae: 2694.2417\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2735.7136 - mae: 2735.7136\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2712.7158 - mae: 2712.7158\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2697.5396 - mae: 2697.5396\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2669.8345 - mae: 2669.8345\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2636.4204 - mae: 2636.4204\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2622.2686 - mae: 2622.2686\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2642.2957 - mae: 2642.2957\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2603.3098 - mae: 2603.3098\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2582.3525 - mae: 2582.3525\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2576.0410 - mae: 2576.0410\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2594.4702 - mae: 2594.4702\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2587.2617 - mae: 2587.2617\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2590.5034 - mae: 2590.5034\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2542.1624 - mae: 2542.1624\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2501.7312 - mae: 2501.7312\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2513.6821 - mae: 2513.6821\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2523.7070 - mae: 2523.7070\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2483.8928 - mae: 2483.8928\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2493.5845 - mae: 2493.5845\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2462.3025 - mae: 2462.3025\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2449.7703 - mae: 2449.7703\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2472.7024 - mae: 2472.7024\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2420.1599 - mae: 2420.1599\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2412.0442 - mae: 2412.0442\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2392.2039 - mae: 2392.2039\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2417.4006 - mae: 2417.4006\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2436.1802 - mae: 2436.1802\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2353.9104 - mae: 2353.9104\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2335.9480 - mae: 2335.9480\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2333.7004 - mae: 2333.7004\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2362.4026 - mae: 2362.4026\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2354.7883 - mae: 2354.7883\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2338.6794 - mae: 2338.6794\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2312.3865 - mae: 2312.3865\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2300.7524 - mae: 2300.7524\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2309.0142 - mae: 2309.0142\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2287.2642 - mae: 2287.2642\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2269.7668 - mae: 2269.7668\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2268.4727 - mae: 2268.4727\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2254.9170 - mae: 2254.9170\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2245.6680 - mae: 2245.6680\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2242.9507 - mae: 2242.9507\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2273.6191 - mae: 2273.6191\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2295.7258 - mae: 2295.7258\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2247.2117 - mae: 2247.2117\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2210.0505 - mae: 2210.0505\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2222.8657 - mae: 2222.8657\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2215.2551 - mae: 2215.2551\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2197.8423 - mae: 2197.8423\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2194.4934 - mae: 2194.4934\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2191.4097 - mae: 2191.4097\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 2173.1333 - mae: 2173.1333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0fb2842c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfoPPiP-7Axi",
        "outputId": "e48eaa32-0460-4003-8e3b-41cf8002613e"
      },
      "source": [
        "# Check the results of our model with test data\n",
        "model_2.evaluate(X_test, y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 1986.9711 - mae: 1986.9711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1986.9710693359375, 1986.9710693359375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0shwhIp7FRv"
      },
      "source": [
        "We can see a clear improvement with the changed optimizer. Let's try some more "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hMyn69T7OOy",
        "outputId": "aebde185-1317-4c44-ed5c-53546958bada"
      },
      "source": [
        "# Let's try a model with a different learning rate and one more hidden layer\n",
        "tf.random.set_seed=42\n",
        "# 1.Create a model\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(X_train, y_train, epochs = 100)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 11314.4160 - mae: 11314.4160\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7296.1606 - mae: 7296.1606\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6822.2778 - mae: 6822.2778\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6613.1118 - mae: 6613.1118\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6531.8442 - mae: 6531.8442\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6231.5352 - mae: 6231.5352\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5815.0703 - mae: 5815.0703\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4930.5410 - mae: 4930.5410\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3933.1089 - mae: 3933.1089\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3886.8911 - mae: 3886.8911\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3249.7505 - mae: 3249.7505\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3284.3779 - mae: 3284.3779\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3289.9590 - mae: 3289.9590\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2943.9331 - mae: 2943.9331\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2824.8767 - mae: 2824.8767\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3086.7166 - mae: 3086.7166\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2941.0498 - mae: 2941.0498\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2753.4429 - mae: 2753.4429\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2684.0005 - mae: 2684.0005\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2727.8430 - mae: 2727.8430\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2748.2822 - mae: 2748.2822\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2556.8987 - mae: 2556.8987\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2624.3076 - mae: 2624.3076\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2581.5723 - mae: 2581.5723\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2580.2134 - mae: 2580.2134\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2526.9045 - mae: 2526.9045\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2522.5085 - mae: 2522.5085\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2655.6672 - mae: 2655.6672\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2653.7476 - mae: 2653.7476\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2404.1499 - mae: 2404.1499\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2375.3718 - mae: 2375.3718\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2476.5610 - mae: 2476.5610\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2253.4978 - mae: 2253.4978\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2349.5920 - mae: 2349.5920\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2309.7725 - mae: 2309.7725\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2249.9585 - mae: 2249.9585\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2341.8328 - mae: 2341.8328\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2262.0842 - mae: 2262.0842\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2331.2786 - mae: 2331.2786\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2525.5911 - mae: 2525.5911\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2205.2559 - mae: 2205.2559\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2200.8320 - mae: 2200.8320\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2279.7656 - mae: 2279.7656\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2225.0708 - mae: 2225.0708\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2302.9304 - mae: 2302.9304\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2287.1975 - mae: 2287.1975\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2492.1653 - mae: 2492.1653\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2387.1135 - mae: 2387.1135\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2216.7554 - mae: 2216.7554\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2209.1260 - mae: 2209.1260\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2297.4441 - mae: 2297.4441\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2166.3027 - mae: 2166.3027\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2182.5852 - mae: 2182.5852\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2211.6016 - mae: 2211.6016\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2393.6558 - mae: 2393.6558\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2172.5740 - mae: 2172.5740\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2175.6223 - mae: 2175.6223\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2351.2061 - mae: 2351.2061\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2320.8611 - mae: 2320.8611\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2203.1204 - mae: 2203.1204\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2222.6709 - mae: 2222.6709\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2313.3945 - mae: 2313.3945\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2151.5259 - mae: 2151.5259\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2320.6909 - mae: 2320.6909\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2413.7781 - mae: 2413.7781\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2332.6145 - mae: 2332.6145\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2260.0706 - mae: 2260.0706\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2150.7832 - mae: 2150.7832\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2291.2153 - mae: 2291.2153\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2305.3164 - mae: 2305.3164\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2421.3872 - mae: 2421.3872\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2543.4670 - mae: 2543.4670\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2219.8364 - mae: 2219.8364\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2349.3567 - mae: 2349.3567\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2369.4995 - mae: 2369.4995\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2193.9043 - mae: 2193.9043\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2447.2913 - mae: 2447.2913\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2285.1987 - mae: 2285.1987\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2192.9104 - mae: 2192.9104\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2265.0286 - mae: 2265.0286\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2111.0728 - mae: 2111.0728\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2154.7239 - mae: 2154.7239\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2273.1948 - mae: 2273.1948\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2229.8228 - mae: 2229.8228\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2261.6553 - mae: 2261.6553\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2230.1396 - mae: 2230.1396\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2218.4377 - mae: 2218.4377\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2283.6230 - mae: 2283.6230\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2215.5137 - mae: 2215.5137\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2349.4087 - mae: 2349.4087\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2339.8477 - mae: 2339.8477\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2313.6521 - mae: 2313.6521\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2289.6550 - mae: 2289.6550\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2298.6624 - mae: 2298.6624\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2408.2786 - mae: 2408.2786\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2224.9287 - mae: 2224.9287\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 2218.9966 - mae: 2218.9966\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2233.5596 - mae: 2233.5596\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2149.9868 - mae: 2149.9868\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 2215.8901 - mae: 2215.8901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0fb0e98b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy_ZWPCJ7cL1",
        "outputId": "24df7fd2-3df5-4822-9106-9341b8b8190e"
      },
      "source": [
        "# Check the results of our model with test data\n",
        "model_3.evaluate(X_test, y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 1840.7301 - mae: 1840.7301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1840.7301025390625, 1840.7301025390625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCL0AjnA74Dp",
        "outputId": "95de9b6e-acc8-4e04-9dbd-418fbce49f3e"
      },
      "source": [
        "# Let's try a model with more epochs\n",
        "tf.random.set_seed=42\n",
        "# 1.Create a model\n",
        "model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_4.fit(X_train, y_train, epochs = 300, verbose = 0)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0fb52ec8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEUWEC528LsP",
        "outputId": "c3049881-cbd0-4f6a-b73d-9c9aff7bdee8"
      },
      "source": [
        "# Check the results of our model with test data\n",
        "model_4.evaluate(X_test, y_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 1483.9738 - mae: 1483.9738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1483.9737548828125, 1483.9737548828125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFm8Pno-8M0N"
      },
      "source": [
        "That's a pretty good improvement! Let's try more! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puaNKn_G806c",
        "outputId": "ee22dc29-d6fd-4a3d-ff35-0381718040d1"
      },
      "source": [
        "# Let's try a model with more epochs\n",
        "tf.random.set_seed=42\n",
        "# 1.Create a model\n",
        "model_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_5.fit(X_train, y_train, epochs = 300, verbose = 0)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0faed81410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IadHFK5l9K7c",
        "outputId": "11b8e906-9cd8-4de8-e7bf-95bb94cae22a"
      },
      "source": [
        "# Check the results of our model with test data\n",
        "model_5.evaluate(X_test, y_test)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 1556.0930 - mae: 1556.0930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1556.093017578125, 1556.093017578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vz36OyQX9Mlc",
        "outputId": "ee5b7788-b2b6-4b97-e969-93f1eccb91fa"
      },
      "source": [
        "# Now let's compare all our models\n",
        "all_models = [[\"model_1\", tf.metrics.mean_absolute_error(y_test, tf.squeeze(model_1.predict(X_test))).numpy(), tf.metrics.mean_squared_error(y_test, tf.squeeze(model_1.predict(X_test))).numpy()],\n",
        "              [\"model_2\", tf.metrics.mean_absolute_error(y_test, tf.squeeze(model_2.predict(X_test))).numpy(), tf.metrics.mean_squared_error(y_test, tf.squeeze(model_2.predict(X_test))).numpy()],\n",
        "              [\"model_3\", tf.metrics.mean_absolute_error(y_test, tf.squeeze(model_3.predict(X_test))).numpy(), tf.metrics.mean_squared_error(y_test, tf.squeeze(model_3.predict(X_test))).numpy()],\n",
        "              [\"model_4\", tf.metrics.mean_absolute_error(y_test, tf.squeeze(model_4.predict(X_test))).numpy(), tf.metrics.mean_squared_error(y_test, tf.squeeze(model_4.predict(X_test))).numpy()],\n",
        "              [\"model_5\", tf.metrics.mean_absolute_error(y_test, tf.squeeze(model_5.predict(X_test))).numpy(), tf.metrics.mean_squared_error(y_test, tf.squeeze(model_5.predict(X_test))).numpy()]]\n",
        "\n",
        "models_df = pd.DataFrame(all_models, columns=[\"model\", \"mae\", \"mse\"])\n",
        "\n",
        "models_df"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>8651.733398</td>\n",
              "      <td>166145600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>1986.971069</td>\n",
              "      <td>23350190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>1840.729980</td>\n",
              "      <td>21778672.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>model_4</td>\n",
              "      <td>1483.973877</td>\n",
              "      <td>19420150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>model_5</td>\n",
              "      <td>1556.093140</td>\n",
              "      <td>19618370.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model          mae          mse\n",
              "0  model_1  8651.733398  166145600.0\n",
              "1  model_2  1986.971069   23350190.0\n",
              "2  model_3  1840.729980   21778672.0\n",
              "3  model_4  1483.973877   19420150.0\n",
              "4  model_5  1556.093140   19618370.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_IB72G6AdTn"
      },
      "source": [
        "Preprocessing data (normalization and standardization)\n",
        "\n",
        "To prepare our data, we can use the scikit learn's `MinMaxScalar`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_xU2Rk55MxZj",
        "outputId": "6bb50edd-1a63-43b2-fb35-360cc9306fcb"
      },
      "source": [
        "insurance.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6xIrDnbELv0"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Set X and y again\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Split the data again into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the column transformer with our training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transforming training and test data with MinMaxScalar and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9ilOd1NKrLP",
        "outputId": "d22c1de8-8515-4471-985b-8fe0e6596169"
      },
      "source": [
        "# Let's check how our data looks like now\n",
        "X_train.loc[0]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNgJYFZlPr5R",
        "outputId": "270162a2-4ffc-4fb2-d637-033e4aee4924"
      },
      "source": [
        "X_train_normal[0]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgab8wVxPuSc",
        "outputId": "7f0f2d7f-76dc-411a-98bf-56eaf89df993"
      },
      "source": [
        "# Let's check the shapes\n",
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq4JlvX-QWHM"
      },
      "source": [
        "Let's build a neural network model to fit on our normalized and encoded data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Czjhu_iQqDR",
        "outputId": "63550e3b-d9e0-44bc-8862-5ffcaf501053"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed = 42\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X_train_normal, y_train, epochs=200, verbose=0)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f996ae210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOJZaG1gRlMP",
        "outputId": "32e2a42e-ef83-44ee-be2c-4d02d112ada6"
      },
      "source": [
        "#Evaluate the model\n",
        "model.evaluate(X_test_normal, y_test)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 1589.6372 - mae: 1589.6372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1589.63720703125, 1589.63720703125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbWNE5URRsBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}